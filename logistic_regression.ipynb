{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP54lFRgnAx7dApcfc8M0zG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingYannn/Leetcode/blob/master/logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUNWOjji1GeE"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oef2CPFd1ibY"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "class LogicRegression(object):\r\n",
        "    def __init__(self, learning_rate, iteration=50, seed=0):\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.iteration = iteration\r\n",
        "        self.seed = seed\r\n",
        "\r\n",
        "    def sigmoid(self, x, w):\r\n",
        "        '''sigmoid function.'''\r\n",
        "        return 1.0 / (1.0 + exp(np.dot(w, x)))\r\n",
        "\r\n",
        "    def sigmoid_gd(self, xs, ys):\r\n",
        "        # 梯度上升(求交叉熵最大值)\r\n",
        "         sgd = self.learning_rate * (xi * yi - (np.exp(np.dot(self.W, xs)) * xi) / ( 1 + np.exp(np.dot(self.W, xs))))\r\n",
        "         return sgd\r\n",
        "\r\n",
        "    def loss(self, xs, ys):\r\n",
        "        ''' get loss\r\n",
        "        @param Y: label value.\r\n",
        "        @param y_hat: predict value.\r\n",
        "        '''\r\n",
        "        # 1 / N  * \\sum (y_i * logy_hat_i + (1-y_i) * log(1-y_hat_i))\r\n",
        "        y_hats = self.sigmoid(xs)\r\n",
        "        losses = ys * np.log(y_hats) + (1-ys) * log(1-y_hats)\r\n",
        "        loss = np.sum(losses) / (len(ys) + 0.0001)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def fit(self, X, Y):\r\n",
        "        '''train \r\n",
        "        '''\r\n",
        "        feat_nums, data_nums = X.shape\r\n",
        "        # W : (D * 1)\r\n",
        "        self.W = np.random.uniform(-1.0, 1.0, [feat_nums])\r\n",
        "        for i in range(self.iteration):\r\n",
        "            # SGD\r\n",
        "            for j in range(data_nums):\r\n",
        "                loss = self.loss(xs, ys)\r\n",
        "                if loss <= self.thresh:\r\n",
        "                    break\r\n",
        "                self.W += sigmoid_gd(xs, ys) \r\n",
        "\r\n",
        "    def predict(self, x):\r\n",
        "        p = self.sigmoid(x, self.W)\r\n",
        "        if p>0.5:\r\n",
        "            return 1\r\n",
        "        else: return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vUAWpl1-s-f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "learning_rate = 0.01\r\n",
        "epochs = 25\r\n",
        "batch_size = 100\r\n",
        "display_step = 1\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HemEuezjAFPC"
      },
      "source": [
        "# logistic regression\r\n",
        "from __future__ import print_function\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "\r\n",
        "#加载tensorflow中自带的数据集mnist 手写体识别\r\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\r\n",
        "\r\n",
        "# 设置相应的参数\r\n",
        "learning_rate = 0.01   #学习率\r\n",
        "training_epochs = 25    #epoch 即完整训练数据集多少次\r\n",
        "batch_size = 100        #batch 即每次训练用多少数据\r\n",
        "display_step = 1        #每隔多少个epoch展示一下结果\r\n",
        "\r\n",
        "# 定义输入和输出的维度，占位符\r\n",
        "x = tf.placeholder(tf.float32, [None, 784])\r\n",
        "y = tf.placeholder(tf.float32,[None, 10])\r\n",
        "\r\n",
        "# 定义logistic的权重和偏置\r\n",
        "W = tf.Variable(tf.zeros([784,10]))\r\n",
        "b = tf.Variable(tf.zeros([10]))\r\n",
        "\r\n",
        "# 建立模型，为多分类的logistic模型\r\n",
        "pred = tf.nn.softmax(tf.matmul(x,W) + b)\r\n",
        "\r\n",
        "# 定义损失函数为交叉熵\r\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))\r\n",
        "\r\n",
        "# 定义优化算法为：随机梯度提升算法\r\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\r\n",
        "\r\n",
        "# 初始化参数\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "\r\n",
        "# 构建图\r\n",
        "with tf.Session() as sess:\r\n",
        "\r\n",
        "    #首先初始化参数\r\n",
        "    sess.run(init)\r\n",
        "    \r\n",
        "#     training cycle\r\n",
        "    for epoch in range(training_epochs):\r\n",
        "        avg_cost = 0.\r\n",
        "        #定义总共有多少个batch\r\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\r\n",
        "        \r\n",
        "        for i in range(total_batch):\r\n",
        "            #取数据\r\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n",
        "            _, c = sess.run([optimizer, cost], feed_dict={x:batch_xs, y:batch_ys})\r\n",
        "            \r\n",
        "#           平均损失\r\n",
        "            avg_cost += c/total_batch\r\n",
        "        #展示结果\r\n",
        "        if (epoch+1) % display_step == 0:\r\n",
        "            print(\"Epoch:\",\"%02d\" %(epoch+1),'cost=',\"{:.9f}\".format(avg_cost))\r\n",
        "    print(\"Optimization Finished!\")\r\n",
        "    \r\n",
        "#   用测试数据进行测试\r\n",
        "    correct_prediction = tf.equal(tf.arg_max(pred,1),tf.arg_max(y,1))\r\n",
        "#定义准确率\r\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\r\n",
        "    print(\"Accracy:\",sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels}))\r\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}